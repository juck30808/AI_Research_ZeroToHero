{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c9d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cdb1422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current stable release for CPU and GPU\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26800991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3834993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cti110016\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nNo module named 'tensorflow.python.feature_column.feature_column_v2_types'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1086\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1087\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m )\n\u001b[1;32m---> 44\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0maudio_classification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAudioClassificationPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mautomatic_speech_recognition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutomaticSpeechRecognitionPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\audio_classification.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madd_end_docstrings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPIPELINE_INIT_ARGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_processing_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseImageProcessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodelcard\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelCard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfiguration_auto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\modelcard.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m )\n\u001b[1;32m---> 48\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtraining_args\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m from .utils import (\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\training_args.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdebug_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m from .trainer_utils import (\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mEvaluationStrategy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\trainer_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0meager_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\feature_column\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_StateManagerImpl\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mStateManager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column_v2_types\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFeatureColumn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize_feature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.feature_column.feature_column_v2_types'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CTI110~1\\AppData\\Local\\Temp/ipykernel_22612/1297550631.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sentiment-analysis\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#使用情感分析\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m classifier(\n\u001b[0;32m      5\u001b[0m     [\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1074\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m             \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1077\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m   1089\u001b[0m                 \u001b[1;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m                 \u001b[1;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nNo module named 'tensorflow.python.feature_column.feature_column_v2_types'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\") #使用情感分析\n",
    "classifier(\n",
    "    [\n",
    "        \"寶寶覺得苦，但寶寶不說\",\n",
    "        \"我愛寶寶\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd8bc52",
   "metadata": {},
   "source": [
    "## 1.從  HuggingFace 下載 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果沒有裝 Hugging Face Datasets 的 Library 的話，可以用這個指令來裝 pip install datasets\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a46bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用下面的程式碼，可以先來看資料的資訊。用load_dataset_builder 不會把資料下載下來。\n",
    "\n",
    "from datasets import load_dataset_builder\n",
    "ds_builder = load_dataset_builder(\"poem_sentiment\")\n",
    "print(ds_builder.info.description)\n",
    "print(ds_builder.info.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a556e8",
   "metadata": {},
   "source": [
    "## 2.載入本地端的 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5a7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 除了 sentiment = load_dataset(\"poem_sentiment\") 來載入 Hugging Face Hub 上的 dataset。\n",
    "\n",
    "# # 如果要載入 CSV 的 dataset 的話，可以用下面的程式碼：\n",
    "# csv_dataset = load_dataset(\"csv\", data_files=\"my_dataset.csv\")\n",
    "\n",
    "\n",
    "# # 依此類推，我們可以透過這種方式，來載入 txt、JSON 還有pickled dataframe\n",
    "# txt_dataset = load_dataset(\"text\", data_files=\"my_dataset.txt\")\n",
    "# json_dataset = load_dataset(\"json\", data_files=\"my_dataset.jsonl\") #注意這裡用的是 JSON Lines 的格式\n",
    "# pandas_dataset = load_dataset(\"pandas\", data_files=\"my_dataset.pkl\")\n",
    "\n",
    "\n",
    "# #還可以指定分隔符號和欄位，這裡分隔符號就要視你本身的 dataset 而定。\n",
    "# csv_dataset = load_dataset(\"csv\", data_files=\"my_dataset.csv\",sep=\",\",names=[\"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88ec3d3",
   "metadata": {},
   "source": [
    "## 3.載入雲端的 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d1965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 很多時候我們自己的 dataset 放在 AWS S3 或是 Azure Blob 這類的 Object storage 裡面\n",
    "\n",
    "# #這把整個 dataset 載下來的程式碼，如果你不在 Jupyter notebook 裡下載，要在 terminal 裡下載的話，就把驚嘆號給去掉。\n",
    "# dataset_url = \"https://your.dataset/url\"\n",
    "# !wget {dataset_url}\n",
    "\n",
    "\n",
    "# #也可以直接把網址放進去，來載入遠端的 dataset。\n",
    "# url = \"https://your.dataset/url\"\n",
    "# remote_dataset = load_dataset(\"csv\", data_files=url)\n",
    "\n",
    "\n",
    "# #很多時候，你會把 training dataset 和 test dataset 分開成不同的檔案，可以用下面的程式碼一口氣合併且載入 dataset。這是一個很方便的做法。\n",
    "# url = \"https://your.dataset/url\"\n",
    "# data_files = {\n",
    "#     \"train\": url + \"train.json.gz\",\n",
    "#     \"test\": url + \"json.gz\",\n",
    "# }\n",
    "\n",
    "# # 這裡可以省下解壓縮 gz 檔的動作，直接 load 成 dataset，非常的方便實用\n",
    "# remote_dataset = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3db29c",
   "metadata": {},
   "source": [
    "## Hugging Face Datasets Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d48de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "sentiment = load_dataset(\"poem_sentiment\")\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd764e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 接著我們可以來切資料\n",
    "train_ds = sentiment[\"train\"]\n",
    "valid_ds = sentiment[\"validation\"]\n",
    "test_ds = sentiment[\"test\"]\n",
    "# 我們也可以用這種方式來切資料\n",
    "dataset_train = load_dataset(\"rotten_tomatoes\", split=\"train\")\n",
    "\n",
    "\n",
    "\n",
    "# 接著可以直接把 dataset 轉成 Pandas\n",
    "import pandas as pd\n",
    "sentiment.set_format(type=\"pandas\")\n",
    "df = sentiment[\"train\"][:]\n",
    "df.head(10)\n",
    "\n",
    "\n",
    "# 我們可以使用int2str 來把 label 轉成文字。\n",
    "def label_int2str(row):\n",
    "    return sentiment[\"train\"].features[\"label\"].int2str(row)\n",
    "df[\"label_name\"] = df[\"label\"].apply(label_int2str)\n",
    "df.head(10)\n",
    "\n",
    "\n",
    "# 我們也可以畫出圖片，來看看這個dataset 的 label 分佈。\n",
    "import matplotlib.pyplot as plt\n",
    "df[\"label_name\"].value_counts().plot.barh()\n",
    "plt.title(\"Poem Classes\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 不要pandas 格式的話，可以這樣子改回來\n",
    "sentiment.reset_format()\n",
    "\n",
    "\n",
    "# 也可以把 pandas 處理過的轉成新的 dataset\n",
    "from datasets import Dataset\n",
    "label_name_dataset = Dataset.from_pandas(df)\n",
    "label_name_dataset\n",
    "\n",
    "\n",
    "# 可以這樣子 shuffle 資料\n",
    "sentiment_train = sentiment[\"train\"].shuffle(seed=5566).select(range(100))\n",
    "\n",
    "\n",
    "# 也可以用 filter，來過濾資料，這裡用詩句的長度。\n",
    "sentiment_filtered = sentiment.filter(lambda x: len(x[\"verse_text\"]) > 30)\n",
    "sentiment_filtered\n",
    "\n",
    "\n",
    "# 當然常見的 map 也是有的，這裡我們把詩句轉成文字長度。注意這裡的batched=True，我們之後還會再見到它。\n",
    "new_dataset = sentiment.map(\n",
    "    lambda x: {\"verse_text\": [ len(o) for o in x[\"verse_text\"] ] }, batched=True\n",
    ")\n",
    "new_dataset['test'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5454a7",
   "metadata": {},
   "source": [
    "## Hugging Face Transformer Pipeline and TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\n",
    "    [\"Only those who will risk going too far can definitely find out how far one can go.\",\n",
    "     \"Baby shark, doo doo doo doo doo doo, Baby shark!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8760ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只要用 TFAutoModel 就可以載入想要的 transformer model 了。程式碼參考如下。\n",
    "from transformers import TFAutoModel\n",
    "tf_model = TFAutoModel.from_pretrained(model_name)\n",
    "\n",
    "# 有的模型存在 PyTorch 的版本，TensorFlow 的版本是不存在的。透過 Hugging Face 能讓你用 TensorFlow 使 PyTorch 的 transformer。\n",
    "# 下面的程式碼中的 xlm-roberta-base，就是只存在於 PyTorch 版本的 transformer。\n",
    "tf_model = TFAutoModel.from_pretrained(\"xlm-roberta-base\", from_pt=True)\n",
    "\n",
    "# 在 Hugging Face 的慣例中，pt 一般就是指 PyTorch ，而 tf 是指 TensorFlow。\n",
    "# 許多內建的功能，都只要再加上 TF 的前綴，就會變成 TensorFlow 版本的功能了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d66a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires the latest pip\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Current stable release for CPU and GPU\n",
    "!pip install tensorflow\n",
    "\n",
    "# Or try the preview build (unstable)\n",
    "!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c210f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
