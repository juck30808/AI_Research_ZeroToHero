{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c9d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb1422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current stable release for CPU and GPU\n",
    "!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26800991",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 uninstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3834993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\") #使用情感分析\n",
    "classifier(\n",
    "    [\n",
    "        \"寶寶覺得苦，但寶寶不說\",\n",
    "        \"我愛寶寶\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd8bc52",
   "metadata": {},
   "source": [
    "## 1.從  HuggingFace 下載 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果沒有裝 Hugging Face Datasets 的 Library 的話，可以用這個指令來裝 pip install datasets\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a46bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用下面的程式碼，可以先來看資料的資訊。用load_dataset_builder 不會把資料下載下來。\n",
    "\n",
    "from datasets import load_dataset_builder\n",
    "ds_builder = load_dataset_builder(\"poem_sentiment\")\n",
    "print(ds_builder.info.description)\n",
    "print(ds_builder.info.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a556e8",
   "metadata": {},
   "source": [
    "## 2.載入本地端的 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5a7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 除了 sentiment = load_dataset(\"poem_sentiment\") 來載入 Hugging Face Hub 上的 dataset。\n",
    "\n",
    "# # 如果要載入 CSV 的 dataset 的話，可以用下面的程式碼：\n",
    "# csv_dataset = load_dataset(\"csv\", data_files=\"my_dataset.csv\")\n",
    "\n",
    "\n",
    "# # 依此類推，我們可以透過這種方式，來載入 txt、JSON 還有pickled dataframe\n",
    "# txt_dataset = load_dataset(\"text\", data_files=\"my_dataset.txt\")\n",
    "# json_dataset = load_dataset(\"json\", data_files=\"my_dataset.jsonl\") #注意這裡用的是 JSON Lines 的格式\n",
    "# pandas_dataset = load_dataset(\"pandas\", data_files=\"my_dataset.pkl\")\n",
    "\n",
    "\n",
    "# #還可以指定分隔符號和欄位，這裡分隔符號就要視你本身的 dataset 而定。\n",
    "# csv_dataset = load_dataset(\"csv\", data_files=\"my_dataset.csv\",sep=\",\",names=[\"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88ec3d3",
   "metadata": {},
   "source": [
    "## 3.載入雲端的 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d1965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 很多時候我們自己的 dataset 放在 AWS S3 或是 Azure Blob 這類的 Object storage 裡面\n",
    "\n",
    "# #這把整個 dataset 載下來的程式碼，如果你不在 Jupyter notebook 裡下載，要在 terminal 裡下載的話，就把驚嘆號給去掉。\n",
    "# dataset_url = \"https://your.dataset/url\"\n",
    "# !wget {dataset_url}\n",
    "\n",
    "\n",
    "# #也可以直接把網址放進去，來載入遠端的 dataset。\n",
    "# url = \"https://your.dataset/url\"\n",
    "# remote_dataset = load_dataset(\"csv\", data_files=url)\n",
    "\n",
    "\n",
    "# #很多時候，你會把 training dataset 和 test dataset 分開成不同的檔案，可以用下面的程式碼一口氣合併且載入 dataset。這是一個很方便的做法。\n",
    "# url = \"https://your.dataset/url\"\n",
    "# data_files = {\n",
    "#     \"train\": url + \"train.json.gz\",\n",
    "#     \"test\": url + \"json.gz\",\n",
    "# }\n",
    "\n",
    "# # 這裡可以省下解壓縮 gz 檔的動作，直接 load 成 dataset，非常的方便實用\n",
    "# remote_dataset = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3db29c",
   "metadata": {},
   "source": [
    "## Hugging Face Datasets Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d48de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "sentiment = load_dataset(\"poem_sentiment\")\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd764e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 接著我們可以來切資料\n",
    "train_ds = sentiment[\"train\"]\n",
    "valid_ds = sentiment[\"validation\"]\n",
    "test_ds = sentiment[\"test\"]\n",
    "# 我們也可以用這種方式來切資料\n",
    "dataset_train = load_dataset(\"rotten_tomatoes\", split=\"train\")\n",
    "\n",
    "\n",
    "\n",
    "# 接著可以直接把 dataset 轉成 Pandas\n",
    "import pandas as pd\n",
    "sentiment.set_format(type=\"pandas\")\n",
    "df = sentiment[\"train\"][:]\n",
    "df.head(10)\n",
    "\n",
    "\n",
    "# 我們可以使用int2str 來把 label 轉成文字。\n",
    "def label_int2str(row):\n",
    "    return sentiment[\"train\"].features[\"label\"].int2str(row)\n",
    "df[\"label_name\"] = df[\"label\"].apply(label_int2str)\n",
    "df.head(10)\n",
    "\n",
    "\n",
    "# 我們也可以畫出圖片，來看看這個dataset 的 label 分佈。\n",
    "import matplotlib.pyplot as plt\n",
    "df[\"label_name\"].value_counts().plot.barh()\n",
    "plt.title(\"Poem Classes\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 不要pandas 格式的話，可以這樣子改回來\n",
    "sentiment.reset_format()\n",
    "\n",
    "\n",
    "# 也可以把 pandas 處理過的轉成新的 dataset\n",
    "from datasets import Dataset\n",
    "label_name_dataset = Dataset.from_pandas(df)\n",
    "label_name_dataset\n",
    "\n",
    "\n",
    "# 可以這樣子 shuffle 資料\n",
    "sentiment_train = sentiment[\"train\"].shuffle(seed=5566).select(range(100))\n",
    "\n",
    "\n",
    "# 也可以用 filter，來過濾資料，這裡用詩句的長度。\n",
    "sentiment_filtered = sentiment.filter(lambda x: len(x[\"verse_text\"]) > 30)\n",
    "sentiment_filtered\n",
    "\n",
    "\n",
    "# 當然常見的 map 也是有的，這裡我們把詩句轉成文字長度。注意這裡的batched=True，我們之後還會再見到它。\n",
    "new_dataset = sentiment.map(\n",
    "    lambda x: {\"verse_text\": [ len(o) for o in x[\"verse_text\"] ] }, batched=True\n",
    ")\n",
    "new_dataset['test'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5454a7",
   "metadata": {},
   "source": [
    "## Hugging Face Transformer Pipeline and TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\n",
    "    [\"Only those who will risk going too far can definitely find out how far one can go.\",\n",
    "     \"Baby shark, doo doo doo doo doo doo, Baby shark!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8760ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只要用 TFAutoModel 就可以載入想要的 transformer model 了。程式碼參考如下。\n",
    "from transformers import TFAutoModel\n",
    "tf_model = TFAutoModel.from_pretrained(model_name)\n",
    "\n",
    "# 有的模型存在 PyTorch 的版本，TensorFlow 的版本是不存在的。透過 Hugging Face 能讓你用 TensorFlow 使 PyTorch 的 transformer。\n",
    "# 下面的程式碼中的 xlm-roberta-base，就是只存在於 PyTorch 版本的 transformer。\n",
    "tf_model = TFAutoModel.from_pretrained(\"xlm-roberta-base\", from_pt=True)\n",
    "\n",
    "# 在 Hugging Face 的慣例中，pt 一般就是指 PyTorch ，而 tf 是指 TensorFlow。\n",
    "# 許多內建的功能，都只要再加上 TF 的前綴，就會變成 TensorFlow 版本的功能了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d66a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires the latest pip\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Current stable release for CPU and GPU\n",
    "!pip install tensorflow\n",
    "\n",
    "# Or try the preview build (unstable)\n",
    "!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c210f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
